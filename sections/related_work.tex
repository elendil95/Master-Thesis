%IMPLEMENT IS THE DIAGRAM DEPICTING WORDLISTS AND RULES.
%REMEMBER TO SPELL-CHECK THIS SECTION AGAIN

%The main process of encoding is hashing not encryption! doont mention encryption if you can.
%encryption is a 2 way fnction cuz you can decrypt andd encypt, there s no decrypt fr hashes.
\section{Related Work}\label{sec:related_work}
Both Password Cracking and Deep Learning are active areas of research developing at a rapid pace.

In section 2, we aim to give an overview of the relevant knowledge in these areas as it relates to our thesis: section \ref{subsec:password_cracking} below will cover the relevant knowledge concerning passwords, while section \ref{subsec:deep-learning} will cover Deep Learning.

\subsection{Password Cracking}\label{subsec:password_cracking}
Password cracking has been around for a long time, and while technology has evolved greatly and continues to do so, the basic concepts have remained relatively similar:
back in 1979, Morris and Thompson were already aware of different ways to attack passwords and defend against such attacks \cite{Thompson1979}.

At the base of all password attacks is the concept of \emph{key space}, i.e the set of all possible passwords of a certain length that use a specific character set \cite{Thompson1979,hash_cat_mask_attack}. 

Key space can be formally defined as the set of all possible keys for some given parameters. The two parameters in question are: the Alphabet of the key (the set of all symbols or characters used in the key), and the length of the key.
Key space can be theoretically infinite, but in practice it is bound by both the alphabet and the key length: in the case of an hexadecimal key of length 10, the key space can be quantified as $16^{10}$ possibilities; on the other hand in the case of the password \texttt{password} (written with lowercase characters only), the key space can be expressed as $26^8$. %convert keyspace sizes to power of 2 to compare the size in bits

Key space is important because it forms the basis from which password cracking techniques work off: if the password is sufficiently complex, an attacker will have to do an exhaustive search of the key space in order to find the password. 
It follows then, that one of principles of password strength is to make the search space big enough to be impractical to search through with current hardware.
This is the reason why users are commonly advised to use a variety of different characters classes in their passwords, and also to use passwords of a certain minimum length.

To ground our discussion of search space in the context of cracking, we should address how passwords are stored in the first place: as Morris and Thompson explain in their paper, the simplest approach is to store the users' passwords in a file or database as they are entered: this is a bad idea as any software bug that causes an accidental disclosure will leave the users exposed, and also because any privileged user can simply look up other users' passwords.

A better approach would be to somehow encrypt the user's password, and store the cypher text: when a user logs in, the string they typed is encrypted, compared with the cypher text and access is granted if it matches. This process is commonly achieved through a one-way cryptographic hash function, while Morris and Thompson use the DES algorithm in their paper.

Simply put, a cryptographic hash function is a mathematical function that encodes a string in a predictable way, mapping an arbitrary amount of input (a message of arbitrary length) to a string of a fixed length (a hash). 

Cryptographic hash functions adhere to strict security standards (hence the adjective \enquote{cryptographic}) but they different from encryption algorithms: %like AES or PGP:
one of the main differences between symmetric encryption and hashing algorithms is that an hashing algorithm is a one-way function, meaning there is no mechanism to decrypt or otherwise reverse the process once the input data has been hashed. 

Another difference can be found in the purpose of hashing algorithms: broadly speaking they are used to compress information about an arbitrary amount of data into a string of a certain length; their main application is to act as \enquote{fingerprints} for a given message, ensuring the integrity and/or authenticity of the data rather than its confidentiality.

We should note that DES - the algorithm used by Morris and Thompson \cite{Thompson1979} to hash passwords, is in fact a symmetric encryption algorithm: the authors used it to encrypt a known constant using the user's password as a key and stored the resulting cypher text.
This in effect gave them the same results as a hashing algorithm: the massage text itself has no value, but the system can encrypt this constant with the string provided by the user and see if the resulting cypher text matches the contents of the database.
Morris and Thompson chose to use DES mostly due to the fact that the algorithm ran quite slowly on computers of the period: it wouldn't be much of an issue to encrypt and check small numbers of passwords, but this slow software implementation would add a lot of time to any cracking attempt.

The reason why hashing algorithms are used with passwords is that in a scenario like the one mentioned before (where whatever string the user types is hashed and compared with the hash in the database) there is no need for decryption: the hash algorithm obscures the input, but its main role its to make sure the password the user enters at login is the same as the one that is stored in the database.
Additionally, the mere possibility of decrypting a user's password might represent a security risk: if a user forgets a password we do not need to  decrypt it and show it to the user, we can simply delete the password and ask him to make a new one. 

Crucially, in order to accomplish this task a hashing algorithm needs to be predictable i.e always output the same string for a given input: this is a propriety an attacker can exploit as we will see shortly. 

When a strong hashing algorithm is used, an attacker will theoretically have to do a key space search in order to crack the users' password: this process will take even more time, as every candidate string/password must be first hashed with the same algorithm and then looked up in the database.

Hashing alone does not solve the problem however, because in reality an attacker would not have to resort to brute-forcing in a majority of cases.

Because the hashing algorithm needs to be predictable, the attacker can start comparing the hashes in the database and draw some conclusion: if some hashes appear many times, they probably hold the plain text of some very common passwords; if the attacker cracks those first and starts looking for similar patterns, he may crack a sizable number of the passwords contained in the database.

Practically, an attacker can exploit this predictability by building a table with pre-computed hashes for all the most common passwords: this technique saves a lot of time since we do not need to encrypt every candidate password before comparing it with the database, and instead we merely look up the hashes from the table in the database. 

These tables are commonly referred to as \emph{Rainbow Tables}, and they are a simplified version of the rule-based techniques covered in section \ref{hash_and_jtr}.

Rainbow tables can be defeated by using \emph{password salting}: salting works by generating a random string that is then appended to the user's password before it is hashed (mainly when the user first creates the account). The authors in \cite{Thompson1979} use a 12-bit random number as their salt, but modern sources suggest the use of longer and more complex salts \cite{NIST_2017}; by generating a unique salt per each user (or even better, per each individual password a user creates), rainbow tables and correlation attacks will be rendered useless as its no longer possible to meaningfully compare hashes; one might attempt to generate tables that contain salts, but this is impractical as it would mean brute-forcing the key space of the salt.
This can be done however in cases where the salt is very short, or alternatively when the system administrators have chosen one fixed salt string with which every password is processed.
The latter mistake its particularly grave, as it defeats the purpose of having salts in the first place.
   
% Let us suppose that an attacker has access to both the hashed passwords of the users and the salts that each password uses: it is conceivable that one might extract all the salts from the database, put them in a dictionary, and use them in a rule-based dictionary attack such as the ones that will be described in section \ref{hash_and_jtr}: if the salt for each user is stored in the database, we do not need to brute-force the key space of the salt: every salt belongs to one of the users, hence we merely need to try them all sequentially on every password candidate. 
% A remedy for such scenario is offered in \cite{NIST_2017} and will be discussed further down. %FUCK ME WITH A RUSTY SPEAR, I HAVE NO IDEA IF THIS IS BS I JUST MADE UP!

For a more current example of how these security practices have evolved since 1979, we can look at the National Institute of Standards and Technologies' standard SP 800-63-3.
This standard is intended to provide security guidelines for information systems within the US government, and was released in June 2017.

Document SP 800-63-3B \cite{NIST_2017}, provides guidelines on how user secrets (passwords and/or PINs) should be stored.\\
They suggest that user passwords should be between 8 and 64 characters, but advise against enforcing password policies concerning the composition of passwords; instead, they suggest that user passwords be checked against a list of leaked passwords and dictionary words before they are accepted, in order to avoid the use of weak passwords.

When it comes to hashing, they suggest the use of the PBKDF2 and Balloon algorithms; Other hashing algorithms listed as suitable for password storage include HMAC and SHA-3.

Furthermore, they recommend that all passwords be salted with at least a 32bit quantity; to our understanding the standard calls for a unique salt for each user, as opposed to a unique salt for each password. The salts should be stored alongside the hashed password of the user.

In order to foil dictionary attacks even in cases where the attacker has access to the users' salts alongside the hashes, the system should perform an additional iteration of the hashing algorithm using a different 112bits salt that should be secret and stored on separate hardware form the main database.\\
If we were to apply such process before hashing the users' passwords with the standard 32bit salt, this would effectively neutralize all dictionary attacks even when the attacker factors the salts into the process.

To conclude this discussion of password storage and security, we will briefly touch upon our main dataset used in the thesis: the Libero dataset.

The Libero dataset is a JSON formatted document that contains information on roughly 700 thousand users of the italian email provider Libero Mail \cite{libero_leak}.\\
Each user record contains various fields such as  user ID, user name, the associated email address and the user's password in plain text.
These plain text passwords served as the basis for all our experiments (detailed in section \ref{sec:testing_and_evaluation}), in which we attempted to crack the Libero dataset with rule-based password crackers and PassGAN. Because the passwords were provided in plain text, we had to hash them with MD5 in order to crack them.
The fact that our dataset did not contain hashed passwords presented a problem, and called into question the authenticity of the data in our possession: we will go into further detail with this  and the choices we made regarding the cracking process in section \ref{sec:libero}.  

Now that we have a better notion of how passwords are stored, the next section will address how passwords are commonly cracked: specifically, we will use state of the art rule-based password crackers in order to explore the cracking process. % to briefly elucidate on how these tools fit in the greater scope of the paper, PassGAN and other such Deep Learning systems can be seen as a complement to rule-based password crackers, as their output is used as input for rule-based tools in order to practically crack passwords. The interplay between these two sides will be explored in section \ref{sec:testing_and_evaluation}.


%Add a diagram with the process of applying rules and using wordlists
\subsubsection{Rule-Based password crackers} \label{hash_and_jtr}
Unlike other password cracking tools made for brute-forcing passwords, rule-based tools rely on \emph{mangling rules} in order to attack a greater variety of passwords:

Mangling rules are patters that define how a string should be modified, they can be given in either in a regular language or in a more complex form.
Their purpose is to modify each string in a wordlist or dictionary so that one entry in the wordlist can match multiple, similar passwords.

The simplest kind of rules are \emph{masks}: they are a subset of mangling rules whose use will be explained in section \ref{par:brute-force}. Masks are patterns expressed in a regular language, that define what character classes are in a password and at what position: their main function is to shrink the key space of a password when executing brute-force attacks.

\enquote{Proper} mangling rules by contrast are more complex and more expressive, in line with a context-free or context-sensitive language; they will be covered is section \ref{par:rule-based}.
Common examples of rules might be a rule that switches the case of the first letter of the string (mainly in order to capitalize passwords, a common strategy users employ to comply with password composition requirements), or a rule that appends one or two digits to the end of a string. 

Two common rule-based password cracking tools are John The Ripper and \break \mbox{HashCat}\cite{john,hash_cat}: these tools use rules to exploit common patterns in user behaviour in order to optimize the cracking process. Both tools have a variety of techniques an attacker can employ, and we will briefly exemplify their capabilities using HashCat as an example \cite{hash_cat_wiki}:

In both tools there are three categories of attacks that can be carried out: brute-force attacks, dictionaries attacks and rule-based attacks: these can be combined and tweaked in various ways depending on the desired result, and there is a degree of overlap between each.


\begin{itemize}
\item Brute-force attacks try every possible combination of characters within a defined pattern, and thus closely relate to key space search. 
\item Dictionary attacks use a dictionary of words or passwords as a source for password candidates, that are hashed and checked against the target to see if any of them match
\item Rule-based attacks are an evolution of Dictionary attacks, in which the dictionary's effectiveness is boosted by some mangling rules that change the words in ways that reflect common patterns in user-generated passwords.
\end{itemize}

HashCat distinguishes between brute-force attacks and wordlist-based attacks with two separate modes (a mode is a setting that defines the kind of attack that HashCat should carry out), but there is no such distinction between wordlist-based attacks and rule-based attacks: instead rules are an optional parameter one can use in wordlist attack mode to greatly increase the effectiveness of the wordlist. The following three sections will cover HashCat's attack strategies by the different modes present in the software. 

\paragraph{Brute-force attacks}\label{par:brute-force}
The simplest of these modes is \emph{Mask attack} mode, used to carry out brute-force attacks as we mentioned previously: a mask attack is essentially an optimized version of key space search, meant to attack simpler passwords while shrinking the key space search. 
Instead of searching the total space for a password of length $x$, we define a simple regular pattern expressing the what character classes are there and at which position, saving us a substantial amount of processing time.
For example if we have a password like \texttt{Benjamin86} or \texttt{Iloveyou02}, we can capture both examples by defining a pattern to be a ten-character string with eight lowercase or uppercase letters and two numbers at the end; This is referred to as a \emph{Mask} in HashCat's documentation:

In a classic brute-force attack we would deal with a search space of $62^{10}$ (or roughly $8 \times 10^{17}$ combinations), but thanks to the above-mentioned mask we can reduce our search space to around $4 \times 10^{13}$ possibilities if we assume that the first character in the string is the only one that can be uppercase.
Furthermore we can use the \texttt{--increment } option in HashCat to apply this mask recursively, to all strings up to ten characters: this allows us to match shorter passwords that follow the same pattern.

This method is rather simplistic and not very flexible, but exemplifies some of the ways in which attackers can optimize key space attacks.

\paragraph{Dictionary attacks}
The main mode of operation oh HashCat \emph{straight} mode, that performs a dictionary attack: in this mode, the program is fed a wordlist/dictionary, and tries each entry the wordlist as a password candidate. Because of its simplicity, such a dictionary attack works best with a wordlist composed of leaked passwords; the aim is to target very common passwords and users that re-use passwords, but the effectiveness of such an attack can increase significantly depending on what wordlist is used.

Dictionary attacks can be further enhanced by combining them in various ways: one approach would be to use two wordlists and append/prepend each entry in the second one to each entry in the first.\\ 
The second wordlist might be a natural language dictionary or simply anther wordlist of plain-text leaked passwords. This is called \emph{Combinator attack} mode in HashCat. 

We might also want to use the output of a mask attack as our second wordlist: if we use the patterns described in the Mask Attack mode to generate strings or number sequences we combine with a wordlist, we will obtain a more targeted and effective version of the Mask Attack method. 

For example if we know that a good deal of the passwords we want to extract are strings with numbers appended to the end, we might run a mask that generates combinations of 0 to 4 digits and then combine the output of that with our wordlist. This is called \emph{Hybrid attack} mode in HashCat.

\paragraph{Rule-based attacks}\label{par:rule-based}
Finally we come to rule-based attacks, In short they are an extension of all the methods described above. 
As we said previously  rule-based attacks do not have a dedicated mode, but instead they are often used in \emph{straight} mode alongside a wordlist in order to boost the number of passwords found by that wordlist.

Rules are flexible and allow for more thorough definition of the patterns that may appear in a password, going beyond the capabilities of the regular language used with Masks.
Patterns can be created independently of the size and characteristics of the passwords, and they are not limited to a fixed patterns; there are also flow control statements and options to apply rules only in certain conditions.
There are also options to save password candidates to memory enabling more advanced processing: saved strings can be appended to each password candidate matching certain criteria, reversed and so on...
These more advanced options allow an attacker to emulate the operation of both Combinator and Hybrid attacks using just mangling rules. 

Rules are applied once to each entry in a wordlist in a similar way to a combinator attack, but multiple rules can also be be applied sequentially to a memorized password or string.

Rules provide a more efficient way to tackle password cracking since their greater flexibility means that an attacker need not know as much about their target or about the nature of the passwords he is trying to crack. 

In order to get a better idea of how rules are used we can look at the \emph{best64} rules, which contain around 70 commonly used mangling rules. The two examples below are taken from \texttt{best64.rule}, a version of the best64 rules that is commonly distributed with HashCat:
\begin{verbatim}
## nothing, reverse, case... base stuff
:
r
u
T0
\end{verbatim}

The rules above are rather simple, they simply reverse a string, toggle each character's case or toggle the case of the first character: as we can see these rules already reflect some common patters used by users, such as using common words spelled backwards or toggling a word's case as a way to comply with password policies.
Further down in the same file we can find some more complex rules:
\begin{verbatim}
## leetify
so0
si1
se3
\end{verbatim}

The substitution rules above are designed to defeat a common practice in user-generated passwords, leet speak: this is the practice of changing letters in passwords with numbers that look similar in an attempt to fit within character class requirements in passwords. 

\paragraph{Using HashCat}
In this section we will give an example of how rule-based password crackers are used in practice, using our experience with HashCat and the Libero dataset as reference. To see how we used HashCat and the Libero passwords in our thesis, refer to section \ref{sec:testing_and_evaluation}.

When running a dictionary attack with HashCat (and other rule-based password crackers), an attacker needs three main pieces of data: a target file containing hashed passwords to be cracked, a wordlist, and optionally a set of rules.
Additionally, one needs to know the type of hash the passwords are encoded with.

Let us give an example of a HashCat command we used in our thesis to perform a dictionary attack using rules, and walk through the various parameters (Note that the red arrows are simply a visual aid to indicate line wrapping, to make the command fit on the page):

\begin{lstlisting}[breaklines=true,postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space}]
hashcat -a 0 -m 0 test_10c.hash /usr/share/hashcat/wordlist/rockyou.txt -r /usr/share/hashcat/rules/best64.rule
\end{lstlisting}

Starting from the left:
\begin{itemize}
\item The first parameter \texttt{-a} indicates the attack mode, the value 0 equals to straight mode in this case for a dictionary attack.

\item The second parameter \texttt{-m} indicates the hash type, hash type number 0 is MD5. As we mentioned previously (towards the end of section \ref{subsec:password_cracking}), we chose to hash the plain text passwords in the Libero dataset with MD5 for the purposes of testing.

\item The third parameter is the target, the set of passwords to be cracked: here we used \texttt{test\_10c.hash}, which is a sub-set of the Libero dataset (further details in section \ref{subsec:passgan-testing}).

\item The fourth parameter is the wordlist to use: here we used \texttt{RockYou}, a popular wordlist composed of more than 14 million passwords from various data breaches. It often comes packaged with HashCat.

\item The fifth parameter \texttt{-r} tells HashCat that we want to use rules.

\item The sixth parameter is the ruleset that we want to use. In this particular instance we have used \texttt{best64.rule}, the same ruleset we have taken the example rules from.    
\end{itemize}

Running this command will print the cracked passwords to standard output as they are found, in the format \texttt{hash:plaintext}, alternatively it is also possible to save the results to a file with the \texttt{-o} option.

We should also note that in this example we did not show how to deal with salted passwords: as we explain in section \ref{sec:libero}, the Libero dataset did not come with any salts, so we do not deal with them in this paper.
